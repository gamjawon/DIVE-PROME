import pandas as pd
import requests
import json
import time
import numpy as np
from geopy.distance import geodesic
import re
import os
from datetime import datetime, timedelta

class RoadWidthIntegrator:
    def __init__(self, kakao_api_key):
        self.api_key = kakao_api_key
        self.headers = {"Authorization": f"KakaoAK {kakao_api_key}"}
        self.base_url = "https://dapi.kakao.com/v2/local"
        
        # API í˜¸ì¶œ ì œí•œ ê´€ë¦¬
        self.daily_limit = 300000  # ì¼ì¼ í˜¸ì¶œ ì œí•œ
        self.per_second_limit = 10  # ì´ˆë‹¹ í˜¸ì¶œ ì œí•œ
        self.call_count = 0
        self.start_time = datetime.now()
        self.last_call_time = 0
        
        # ì§„í–‰ìƒí™© ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜
        self.checkpoint_interval = 100  # 100ê°œë§ˆë‹¤ ì €ì¥
        self.checkpoint_file = "checkpoint_progress.json"
        
    def load_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì—ì„œ ì§„í–‰ìƒí™© ë¡œë“œ"""
        if os.path.exists(self.checkpoint_file):
            try:
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return None
        return None
    
    def save_checkpoint(self, index, results):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint_data = {
            'last_processed_index': index,
            'processed_count': len(results),
            'timestamp': datetime.now().isoformat(),
            'results': results
        }
        with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
    
    def check_api_limits(self):
        """API í˜¸ì¶œ ì œí•œ í™•ì¸ ë° ëŒ€ê¸°"""
        current_time = time.time()
        
        # ì´ˆë‹¹ ì œí•œ í™•ì¸
        time_since_last_call = current_time - self.last_call_time
        if time_since_last_call < (1.0 / self.per_second_limit):
            sleep_time = (1.0 / self.per_second_limit) - time_since_last_call
            print(f"â³ API ì œí•œìœ¼ë¡œ {sleep_time:.2f}ì´ˆ ëŒ€ê¸°...")
            time.sleep(sleep_time)
        
        # ì¼ì¼ ì œí•œ í™•ì¸
        if self.call_count >= self.daily_limit:
            elapsed_time = datetime.now() - self.start_time
            if elapsed_time.total_seconds() < 86400:  # 24ì‹œê°„
                wait_time = 86400 - elapsed_time.total_seconds()
                print(f"ğŸš« ì¼ì¼ API í˜¸ì¶œ ì œí•œ ë„ë‹¬. {wait_time/3600:.1f}ì‹œê°„ í›„ ì¬ì‹œì‘í•˜ì„¸ìš”.")
                return False
        
        self.last_call_time = time.time()
        self.call_count += 1
        return True
    
    def safe_api_call(self, url, params, max_retries=3):
        """ì•ˆì „í•œ API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        for attempt in range(max_retries):
            try:
                # API ì œí•œ í™•ì¸
                if not self.check_api_limits():
                    return None
                
                response = requests.get(url, headers=self.headers, params=params, timeout=10)
                
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 429:  # Too Many Requests
                    wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    print(f"âš ï¸ API ì œí•œ ì˜¤ë¥˜ (429). {wait_time}ì´ˆ í›„ ì¬ì‹œë„... (ì‹œë„ {attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                elif response.status_code == 500:  # ì„œë²„ ì˜¤ë¥˜
                    wait_time = 5
                    print(f"âš ï¸ ì„œë²„ ì˜¤ë¥˜ (500). {wait_time}ì´ˆ í›„ ì¬ì‹œë„... (ì‹œë„ {attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                    return None
                    
            except requests.exceptions.Timeout:
                print(f"â° íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜. ì¬ì‹œë„... (ì‹œë„ {attempt+1}/{max_retries})")
                time.sleep(2)
            except requests.exceptions.RequestException as e:
                print(f"ğŸŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}. ì¬ì‹œë„... (ì‹œë„ {attempt+1}/{max_retries})")
                time.sleep(2)
        
        return None
    
    def search_address_coordinates(self, road_name, sido="ë¶€ì‚°ê´‘ì—­ì‹œ", sigungu=""):
        """ê°œì„ ëœ ì¢Œí‘œ ê²€ìƒ‰ (ì•ˆì „í•œ API í˜¸ì¶œ ì‚¬ìš©)"""
        try:
            full_address = self.get_full_road_address(road_name, sido, sigungu)
            
            # ì£¼ì†Œ ê²€ìƒ‰ API í˜¸ì¶œ
            url = f"{self.base_url}/search/address.json"
            params = {
                'query': full_address,
                'analyze_type': 'similar'
            }
            
            data = self.safe_api_call(url, params)
            
            if data and data['documents']:
                result = data['documents'][0]
                return {
                    'longitude': float(result['x']),
                    'latitude': float(result['y']),
                    'address_name': result['address_name'],
                    'road_address_name': result.get('road_address_name', ''),
                    'search_query': full_address
                }
            
            # ì£¼ì†Œ ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œë„
            return self.search_keyword_coordinates(full_address)
            
        except Exception as e:
            print(f"ì£¼ì†Œ ê²€ìƒ‰ ì‹¤íŒ¨ ({road_name}): {e}")
            return None
    
    def search_keyword_coordinates(self, keyword):
        """ê°œì„ ëœ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        try:
            url = f"{self.base_url}/search/keyword.json"
            params = {
                'query': keyword,
                'category_group_code': 'FD6',
                'x': 129.0756,
                'y': 35.1796,
                'radius': 5000
            }
            
            data = self.safe_api_call(url, params)
            
            if data and data['documents']:
                result = data['documents'][0]
                return {
                    'longitude': float(result['x']),
                    'latitude': float(result['y']),
                    'address_name': result['address_name'],
                    'road_address_name': result.get('road_address_name', ''),
                    'place_name': result['place_name']
                }
            
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {e}")
            
        return None
    
    def create_coordinate_mapping_with_resume(self, road_width_df):
        """ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥í•œ ì¢Œí‘œ ë§¤í•‘"""
        results = []
        start_index = 0
        
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µêµ¬
        checkpoint = self.load_checkpoint()
        if checkpoint:
            start_index = checkpoint['last_processed_index'] + 1
            results = checkpoint['results']
            print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µêµ¬: {start_index}ë²ˆì§¸ë¶€í„° ì¬ì‹œì‘")
            print(f"ğŸ“Š ê¸°ì¡´ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ")
        
        total_count = len(road_width_df)
        
        for idx in range(start_index, total_count):
            row = road_width_df.iloc[idx]
            
            # ì§„í–‰ìƒí™© í‘œì‹œ
            progress = ((idx + 1) / total_count) * 100
            estimated_remaining = (total_count - idx - 1) * 0.15  # ì´ˆë‹¹ ì•½ 6.7ê°œ ì²˜ë¦¬ ê°€ì •
            
            print(f"Processing {idx+1}/{total_count}: {row['road_name']} ({row['sigungu']}) - {progress:.1f}% ì™„ë£Œ, ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining/60:.1f}ë¶„")
            
            # ì¢Œí‘œ ê²€ìƒ‰
            coord_info = self.search_address_coordinates(
                road_name=row['road_name'],
                sido=row['sido'],
                sigungu=row['sigungu']
            )
            
            if coord_info:
                result_row = row.to_dict()
                result_row.update(coord_info)
                result_row['search_success'] = True
            else:
                result_row = row.to_dict()
                result_row.update({
                    'longitude': None,
                    'latitude': None,
                    'address_name': '',
                    'road_address_name': '',
                    'search_success': False
                })
            
            results.append(result_row)
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (idx + 1) % self.checkpoint_interval == 0:
                self.save_checkpoint(idx, results)
                print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {idx + 1}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
                
                # ì¤‘ê°„ ê²°ê³¼ë„ ì €ì¥
                temp_df = pd.DataFrame(results)
                temp_df.to_csv(f"temp_coordinate_mapping_{idx+1}.csv", index=False, encoding='utf-8-sig')
            
            # API ì œí•œ í™•ì¸
            if self.call_count >= self.daily_limit:
                print(f"ğŸš« ì¼ì¼ API í˜¸ì¶œ ì œí•œ ë„ë‹¬. ì§„í–‰ìƒí™©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"ğŸ“ í˜„ì¬ê¹Œì§€ {len(results)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
                break
        
        # ìµœì¢… ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if results:
            self.save_checkpoint(len(results) - 1, results)
        
        return pd.DataFrame(results)
    
    def get_api_usage_report(self):
        """API ì‚¬ìš©ëŸ‰ ë³´ê³ ì„œ"""
        elapsed_time = datetime.now() - self.start_time
        calls_per_minute = (self.call_count / elapsed_time.total_seconds()) * 60 if elapsed_time.total_seconds() > 0 else 0
        
        print(f"\nğŸ“Š API ì‚¬ìš©ëŸ‰ ë³´ê³ ì„œ:")
        print(f"  ì´ í˜¸ì¶œ ìˆ˜: {self.call_count}")
        print(f"  ê²½ê³¼ ì‹œê°„: {elapsed_time}")
        print(f"  ë¶„ë‹¹ í˜¸ì¶œ ìˆ˜: {calls_per_minute:.1f}")
        print(f"  ë‚¨ì€ ì¼ì¼ í˜¸ì¶œëŸ‰: {self.daily_limit - self.call_count}")

    def load_road_width_csv(self, csv_path):
        """
        ë¶€ì‚°ì‹œ ë„ë¡œêµ¬ê°„ì¡°ì„œ CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  íŒŒì‹±
        
        Args:
            csv_path (str): CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            pd.DataFrame: íŒŒì‹±ëœ ë„ë¡œ í­ ë°ì´í„°
        """
        try:
            # ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
            encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig']
            df = None
            
            for encoding in encodings:
                try:
                    print(f"ì¸ì½”ë”© {encoding}ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì‹œë„...")
                    df = pd.read_csv(csv_path, encoding=encoding)
                    print(f"âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ!")
                    break
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    print(f"âŒ {encoding} ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
                    continue
            
            if df is None:
                raise Exception("ëª¨ë“  ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")
            
            print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° ì •ë³´:")
            print(f"  - ì´ í–‰ ìˆ˜: {len(df)}")
            print(f"  - ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
            print(f"  - ì»¬ëŸ¼ëª…: {list(df.columns)}")
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬ (í•œê¸€ ê¹¨ì§ ë°©ì§€)
            df.columns = df.columns.str.strip()
            
            # ì˜ˆìƒ ì»¬ëŸ¼ëª…ë“¤ (ì¸ì½”ë”© ë¬¸ì œë¡œ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ)
            possible_columns = {
                'sido': ['ì‹œë„ëª…', 'sido', 'Â½ÃƒÂµÂµÂ¸Ã­'],
                'sigungu': ['ì‹œêµ°êµ¬ëª…', 'sigungu', 'Â½ÃƒÂ±ÂºÂ±Â¸Â¸Ã­'], 
                'road_class': ['ë„ë¡œìœ„ê³„', 'road_class', 'ÂµÂµÂ·ÃÃ€Â§Â°Ã¨'],
                'road_name': ['ë„ë¡œëª…', 'road_name', 'ÂµÂµÂ·ÃÂ¸Ã­'],
                'road_type': ['ì¢…ì†êµ¬ë¶„', 'road_type', 'ÃÂ¾Â¼Ã“Â±Â¸ÂºÃ'],
                'length': ['ì—°ì¥', 'length', 'Â¿Â¬Ã€Ã¥'],
                'width': ['í­', 'width', 'Ã†Ã¸']
            }
            
            # ì»¬ëŸ¼ ë§¤í•‘
            column_mapping = {}
            for standard_name, possible_names in possible_columns.items():
                for col in df.columns:
                    if col in possible_names:
                        column_mapping[col] = standard_name
                        break
            
            print(f"ğŸ“ ì»¬ëŸ¼ ë§¤í•‘: {column_mapping}")
            
            # ì»¬ëŸ¼ëª… ë³€ê²½
            df_renamed = df.rename(columns=column_mapping)
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['road_name', 'length', 'width']
            missing_cols = [col for col in required_cols if col not in df_renamed.columns]
            
            if missing_cols:
                print(f"âš ï¸ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
                print("ì»¬ëŸ¼ ìˆœì„œ ê¸°ë°˜ìœ¼ë¡œ ë§¤í•‘ ì‹œë„...")
                
                # ì»¬ëŸ¼ ìˆœì„œ ê¸°ë°˜ ë§¤í•‘ (ì‹œë„ëª…, ì‹œêµ°êµ¬ëª…, ë„ë¡œìœ„ê³„, ë„ë¡œëª…, ì¢…ì†êµ¬ë¶„, ì—°ì¥, í­)
                if len(df.columns) >= 7:
                    df_renamed = df.copy()
                    df_renamed.columns = ['sido', 'sigungu', 'road_class', 'road_name', 'road_type', 'length', 'width']
                    print("âœ… ìˆœì„œ ê¸°ë°˜ ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ")
            
            # ë°ì´í„° ì •ì œ
            road_data = []
            
            for idx, row in df_renamed.iterrows():
                try:
                    # í•„ìˆ˜ ë°ì´í„° ì¶”ì¶œ
                    road_name = str(row.get('road_name', '')).strip()
                    length = float(row.get('length', 0))
                    width = float(row.get('width', 0))
                    
                    # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì„ íƒ
                    if road_name and length > 0 and width > 0:
                        # ì§€ì—­ ì •ë³´ ì¶”ê°€
                        sido = str(row.get('sido', 'ë¶€ì‚°ê´‘ì—­ì‹œ')).strip()
                        sigungu = str(row.get('sigungu', '')).strip()
                        
                        road_data.append({
                            'road_id': str(idx + 1),  # í–‰ ë²ˆí˜¸ë¥¼ IDë¡œ ì‚¬ìš©
                            'sido': sido,
                            'sigungu': sigungu,
                            'road_name': road_name,
                            'length': length,
                            'width': width,
                            'road_class': str(row.get('road_class', '')).strip(),
                            'road_type': str(row.get('road_type', '')).strip()
                        })
                        
                except (ValueError, TypeError) as e:
                    continue
            
            result_df = pd.DataFrame(road_data)
            
            print(f"ğŸ‰ ë°ì´í„° íŒŒì‹± ì™„ë£Œ:")
            print(f"  - ìœ íš¨í•œ ë„ë¡œ ìˆ˜: {len(result_df)}")
            print(f"  - í‰ê·  ë„ë¡œ í­: {result_df['width'].mean():.1f}m")
            print(f"  - ë„ë¡œ í­ ë²”ìœ„: {result_df['width'].min()}m ~ {result_df['width'].max()}m")
            
            # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
            print(f"\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„°:")
            for i, row in result_df.head().iterrows():
                print(f"  {i+1}. {row['road_name']} ({row['sigungu']}) - ì—°ì¥: {row['length']}m, í­: {row['width']}m")
            
            return result_df
            
        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def get_full_road_address(self, road_name, sido="ë¶€ì‚°ê´‘ì—­ì‹œ", sigungu=""):
        """
        ë„ë¡œëª…ìœ¼ë¡œë¶€í„° ì™„ì „í•œ ì£¼ì†Œ ìƒì„±
        
        Args:
            road_name (str): ë„ë¡œëª…
            sido (str): ì‹œë„ëª…
            sigungu (str): ì‹œêµ°êµ¬ëª…
            
        Returns:
            str: ì™„ì „í•œ ì£¼ì†Œ
        """
        # ì£¼ì†Œ êµ¬ì„±
        if sigungu and sigungu != "":
            full_address = f"{sido} {sigungu} {road_name}"
        else:
            full_address = f"{sido} {road_name}"
        
        return full_address.strip()
    
    def calculate_distance(self, coord1, coord2):
        """
        ë‘ ì¢Œí‘œ ê°„ì˜ ê±°ë¦¬ ê³„ì‚° (ë¯¸í„°)
        
        Args:
            coord1 (tuple): (latitude, longitude)
            coord2 (tuple): (latitude, longitude)
            
        Returns:
            float: ê±°ë¦¬ (ë¯¸í„°)
        """
        try:
            return geodesic(coord1, coord2).meters
        except:
            return float('inf')
    
    def create_spatial_grid(self, coords_df, grid_size=0.001):
        """
        ê³µê°„ ê·¸ë¦¬ë“œ ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”ìš©)
        
        Args:
            coords_df (pd.DataFrame): ì¢Œí‘œ ë°ì´í„°
            grid_size (float): ê·¸ë¦¬ë“œ í¬ê¸° (ë„ ë‹¨ìœ„, ì•½ 100m)
            
        Returns:
            dict: ê·¸ë¦¬ë“œë³„ ì¸ë±ìŠ¤ ë”•ì…”ë„ˆë¦¬
        """
        grid_index = {}
        
        for idx, row in coords_df.iterrows():
            if pd.notna(row.get('latitude')) and pd.notna(row.get('longitude')):
                # ê·¸ë¦¬ë“œ ì…€ ê³„ì‚°
                grid_x = int(row['longitude'] / grid_size)
                grid_y = int(row['latitude'] / grid_size)
                grid_key = (grid_x, grid_y)
                
                if grid_key not in grid_index:
                    grid_index[grid_key] = []
                grid_index[grid_key].append(idx)
        
        return grid_index
    
    def get_nearby_grid_cells(self, lat, lon, grid_size=0.001, radius_cells=2):
        """
        ì£¼ë³€ ê·¸ë¦¬ë“œ ì…€ë“¤ ë°˜í™˜
        
        Args:
            lat, lon (float): ê¸°ì¤€ ì¢Œí‘œ
            grid_size (float): ê·¸ë¦¬ë“œ í¬ê¸°
            radius_cells (int): ê²€ìƒ‰ ë°˜ê²½ (ì…€ ê°œìˆ˜)
            
        Returns:
            list: ì£¼ë³€ ê·¸ë¦¬ë“œ ì…€ í‚¤ ë¦¬ìŠ¤íŠ¸
        """
        center_x = int(lon / grid_size)
        center_y = int(lat / grid_size)
        
        nearby_cells = []
        for dx in range(-radius_cells, radius_cells + 1):
            for dy in range(-radius_cells, radius_cells + 1):
                nearby_cells.append((center_x + dx, center_y + dy))
        
        return nearby_cells
    
    def match_road_width_to_links(self, road_coord_df, link_df, max_distance=500):
        """
        ê³µê°„ ì¸ë±ì‹±ì„ ì‚¬ìš©í•œ ìµœì í™”ëœ ë„ë¡œ í­ ë§¤ì¹­
        
        Args:
            road_coord_df (pd.DataFrame): ì¢Œí‘œê°€ í¬í•¨ëœ ë„ë¡œ í­ ë°ì´í„°
            link_df (pd.DataFrame): ë§í¬ ë°ì´í„°
            max_distance (float): ìµœëŒ€ ë§¤ì¹­ ê±°ë¦¬ (ë¯¸í„°)
            
        Returns:
            pd.DataFrame: ë„ë¡œ í­ ì •ë³´ê°€ ì¶”ê°€ëœ ë§í¬ ë°ì´í„°
        """
        # ì¢Œí‘œ ì •ë³´ê°€ ìˆëŠ” ë„ë¡œ ë°ì´í„°ë§Œ ì‚¬ìš©
        valid_roads = road_coord_df[road_coord_df['search_success'] == True].copy()
        
        print(f"ğŸš€ ìµœì í™”ëœ ë§¤ì¹­ ì‹œì‘: {len(valid_roads)}ê°œ ë„ë¡œ, {len(link_df)}ê°œ ë§í¬")
        
        # ë§í¬ ë°ì´í„°ì— ì¤‘ì  ì¢Œí‘œ ì¶”ê°€
        link_df = link_df.copy()
        link_df['mid_latitude'] = (link_df['ë§í¬ì‹œì‘ìœ„ë„'] + link_df['ë§í¬ëìœ„ë„']) / 2
        link_df['mid_longitude'] = (link_df['ë§í¬ì‹œì‘ê²½ë„'] + link_df['ë§í¬ëê²½ë„']) / 2
        
        # ë„ë¡œ í­ ì»¬ëŸ¼ ì´ˆê¸°í™”
        link_df['road_width'] = None
        link_df['matched_road_name'] = None
        link_df['match_distance'] = None
        
        # ë„ë¡œ ë°ì´í„°ì˜ ê³µê°„ ê·¸ë¦¬ë“œ ì¸ë±ìŠ¤ ìƒì„±
        print("ğŸ“ ê³µê°„ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        road_grid = self.create_spatial_grid(valid_roads, grid_size=0.001)
        print(f"âœ… {len(road_grid)}ê°œ ê·¸ë¦¬ë“œ ì…€ ìƒì„±")
        
        # ë§í¬ë³„ë¡œ ë§¤ì¹­ (ê³µê°„ ì¸ë±ìŠ¤ í™œìš©)
        processed_links = 0
        for link_idx, link_row in link_df.iterrows():
            processed_links += 1
            
            if processed_links % 1000 == 0:
                progress = (processed_links / len(link_df)) * 100
                print(f"â³ ë§í¬ ë§¤ì¹­ ì§„í–‰ë¥ : {processed_links}/{len(link_df)} ({progress:.1f}%)")
            
            # ë§í¬ ì¤‘ì  ì¢Œí‘œ
            link_lat = link_row['mid_latitude']
            link_lon = link_row['mid_longitude']
            
            if pd.notna(link_lat) and pd.notna(link_lon):
                # ì£¼ë³€ ê·¸ë¦¬ë“œ ì…€ë“¤ ê²€ìƒ‰
                nearby_cells = self.get_nearby_grid_cells(link_lat, link_lon)
                
                best_distance = float('inf')
                best_road = None
                
                # ì£¼ë³€ ê·¸ë¦¬ë“œì˜ ë„ë¡œë“¤ë§Œ ê²€ì‚¬
                for grid_cell in nearby_cells:
                    if grid_cell in road_grid:
                        for road_idx in road_grid[grid_cell]:
                            road_row = valid_roads.iloc[road_idx]
                            
                            # ê±°ë¦¬ ê³„ì‚°
                            road_coord = (road_row['latitude'], road_row['longitude'])
                            link_coord = (link_lat, link_lon)
                            distance = self.calculate_distance(road_coord, link_coord)
                            
                            # ìµœì  ë§¤ì¹­ ì°¾ê¸°
                            if distance <= max_distance and distance < best_distance:
                                best_distance = distance
                                best_road = road_row
                
                # ë§¤ì¹­ ê²°ê³¼ ì €ì¥
                if best_road is not None:
                    link_df.loc[link_idx, 'road_width'] = best_road['width']
                    link_df.loc[link_idx, 'matched_road_name'] = best_road['road_name']
                    link_df.loc[link_idx, 'match_distance'] = best_distance
        
        # ì¤‘ì  ì¢Œí‘œ ì»¬ëŸ¼ ì œê±° (ì„ì‹œ ì»¬ëŸ¼)
        link_df = link_df.drop(['mid_latitude', 'mid_longitude'], axis=1)
        
        matched_count = link_df['road_width'].notna().sum()
        print(f"ğŸ‰ ë§í¬ ë§¤ì¹­ ì™„ë£Œ: {matched_count}ê°œ ë§í¬ì— ë„ë¡œ í­ ì •ë³´ ì¶”ê°€")
        
        return link_df
    
    def match_road_width_to_nodes(self, road_coord_df, node_df, max_distance=300):
        """
        ê³µê°„ ì¸ë±ì‹±ì„ ì‚¬ìš©í•œ ìµœì í™”ëœ ë…¸ë“œ ë§¤ì¹­
        
        Args:
            road_coord_df (pd.DataFrame): ì¢Œí‘œê°€ í¬í•¨ëœ ë„ë¡œ í­ ë°ì´í„°
            node_df (pd.DataFrame): ë…¸ë“œ ë°ì´í„°
            max_distance (float): ìµœëŒ€ ë§¤ì¹­ ê±°ë¦¬ (ë¯¸í„°)
            
        Returns:
            pd.DataFrame: ë„ë¡œ í­ ì •ë³´ê°€ ì¶”ê°€ëœ ë…¸ë“œ ë°ì´í„°
        """
        # ì¢Œí‘œ ì •ë³´ê°€ ìˆëŠ” ë„ë¡œ ë°ì´í„°ë§Œ ì‚¬ìš©
        valid_roads = road_coord_df[road_coord_df['search_success'] == True].copy()
        
        print(f"ğŸš€ ìµœì í™”ëœ ë…¸ë“œ ë§¤ì¹­ ì‹œì‘: {len(valid_roads)}ê°œ ë„ë¡œ, {len(node_df)}ê°œ ë…¸ë“œ")
        
        # ë…¸ë“œ ë°ì´í„°ì— ë„ë¡œ í­ ì»¬ëŸ¼ ì´ˆê¸°í™”
        node_df = node_df.copy()
        node_df['road_width'] = None
        node_df['matched_road_name'] = None
        node_df['match_distance'] = None
        
        # ë„ë¡œ ë°ì´í„°ì˜ ê³µê°„ ê·¸ë¦¬ë“œ ì¸ë±ìŠ¤ ìƒì„±
        print("ğŸ“ ë…¸ë“œìš© ê³µê°„ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        road_grid = self.create_spatial_grid(valid_roads, grid_size=0.001)
        print(f"âœ… {len(road_grid)}ê°œ ê·¸ë¦¬ë“œ ì…€ ìƒì„±")
        
        # ë…¸ë“œë³„ë¡œ ë§¤ì¹­ (ê³µê°„ ì¸ë±ìŠ¤ í™œìš©)
        processed_nodes = 0
        for node_idx, node_row in node_df.iterrows():
            processed_nodes += 1
            
            if processed_nodes % 1000 == 0:
                progress = (processed_nodes / len(node_df)) * 100
                print(f"â³ ë…¸ë“œ ë§¤ì¹­ ì§„í–‰ë¥ : {processed_nodes}/{len(node_df)} ({progress:.1f}%)")
            
            # ë…¸ë“œ ì¢Œí‘œ
            node_lat = node_row['ìœ„ë„']
            node_lon = node_row['ê²½ë„']
            
            if pd.notna(node_lat) and pd.notna(node_lon):
                # ì£¼ë³€ ê·¸ë¦¬ë“œ ì…€ë“¤ ê²€ìƒ‰
                nearby_cells = self.get_nearby_grid_cells(node_lat, node_lon)
                
                best_distance = float('inf')
                best_road = None
                
                # ì£¼ë³€ ê·¸ë¦¬ë“œì˜ ë„ë¡œë“¤ë§Œ ê²€ì‚¬
                for grid_cell in nearby_cells:
                    if grid_cell in road_grid:
                        for road_idx in road_grid[grid_cell]:
                            road_row = valid_roads.iloc[road_idx]
                            
                            # ê±°ë¦¬ ê³„ì‚°
                            road_coord = (road_row['latitude'], road_row['longitude'])
                            node_coord = (node_lat, node_lon)
                            distance = self.calculate_distance(road_coord, node_coord)
                            
                            # ìµœì  ë§¤ì¹­ ì°¾ê¸°
                            if distance <= max_distance and distance < best_distance:
                                best_distance = distance
                                best_road = road_row
                
                # ë§¤ì¹­ ê²°ê³¼ ì €ì¥
                if best_road is not None:
                    node_df.loc[node_idx, 'road_width'] = best_road['width']
                    node_df.loc[node_idx, 'matched_road_name'] = best_road['road_name']
                    node_df.loc[node_idx, 'match_distance'] = best_distance
        
        matched_count = node_df['road_width'].notna().sum()
        print(f"ğŸ‰ ë…¸ë“œ ë§¤ì¹­ ì™„ë£Œ: {matched_count}ê°œ ë…¸ë“œì— ë„ë¡œ í­ ì •ë³´ ì¶”ê°€")
        
        return node_df
    
    def save_results(self, enhanced_link_df, enhanced_node_df, road_coord_df, output_dir="output"):
        """
        ê²°ê³¼ íŒŒì¼ë“¤ì„ ì €ì¥
        
        Args:
            enhanced_link_df (pd.DataFrame): ë„ë¡œ í­ ì •ë³´ê°€ ì¶”ê°€ëœ ë§í¬ ë°ì´í„°
            enhanced_node_df (pd.DataFrame): ë„ë¡œ í­ ì •ë³´ê°€ ì¶”ê°€ëœ ë…¸ë“œ ë°ì´í„°
            road_coord_df (pd.DataFrame): ì¢Œí‘œ ì •ë³´ê°€ í¬í•¨ëœ ë„ë¡œ ë°ì´í„°
            output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        enhanced_link_df.to_csv(f"{output_dir}/busan_link_with_road_width.csv", index=False, encoding='utf-8-sig')
        enhanced_node_df.to_csv(f"{output_dir}/busan_node_with_road_width.csv", index=False, encoding='utf-8-sig')
        road_coord_df.to_csv(f"{output_dir}/road_coordinate_mapping.csv", index=False, encoding='utf-8-sig')
        
        print(f"ê²°ê³¼ íŒŒì¼ì´ {output_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"- busan_link_with_road_width.csv")
        print(f"- busan_node_with_road_width.csv") 
        print(f"- road_coordinate_mapping.csv")
    
    def generate_summary_report(self, enhanced_link_df, enhanced_node_df, road_coord_df):
        """
        ë§¤ì¹­ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        
        Args:
            enhanced_link_df (pd.DataFrame): ë„ë¡œ í­ ì •ë³´ê°€ ì¶”ê°€ëœ ë§í¬ ë°ì´í„°
            enhanced_node_df (pd.DataFrame): ë„ë¡œ í­ ì •ë³´ê°€ ì¶”ê°€ëœ ë…¸ë“œ ë°ì´í„°
            road_coord_df (pd.DataFrame): ì¢Œí‘œ ì •ë³´ê°€ í¬í•¨ëœ ë„ë¡œ ë°ì´í„°
        """
        # ë„ë¡œ í­ ë°ì´í„°ì—ì„œ ì§€ì—­ë³„ ë¶„í¬
        if 'sigungu' in road_coord_df.columns:
            sigungu_dist = road_coord_df['sigungu'].value_counts()
            print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ë„ë¡œ ë¶„í¬:")
            for district, count in sigungu_dist.head().items():
                print(f"  {district}: {count}ê°œ")
        
        print("\n" + "="*60)
        print("ğŸ—ºï¸ ë„ë¡œ í­ ë°ì´í„° í†µí•© ê²°ê³¼ ë³´ê³ ì„œ")
        print("="*60)
        
        # ì¢Œí‘œ ê²€ìƒ‰ ì„±ê³µë¥ 
        total_roads = len(road_coord_df)
        successful_coords = road_coord_df['search_success'].sum()
        coord_success_rate = (successful_coords / total_roads) * 100
        
        print(f"\nğŸ“ ì¢Œí‘œ ê²€ìƒ‰ ê²°ê³¼:")
        print(f"  ì´ ë„ë¡œ ìˆ˜: {total_roads}ê°œ")
        print(f"  ì¢Œí‘œ ê²€ìƒ‰ ì„±ê³µ: {successful_coords}ê°œ")
        print(f"  ì„±ê³µë¥ : {coord_success_rate:.1f}%")
        
        # ë§í¬ ë§¤ì¹­ ê²°ê³¼
        total_links = len(enhanced_link_df)
        matched_links = enhanced_link_df['road_width'].notna().sum()
        link_match_rate = (matched_links / total_links) * 100
        
        print(f"\nğŸ”— ë§í¬ ë°ì´í„° ë§¤ì¹­ ê²°ê³¼:")
        print(f"  ì´ ë§í¬ ìˆ˜: {total_links}ê°œ")
        print(f"  ë„ë¡œ í­ ë§¤ì¹­ ì„±ê³µ: {matched_links}ê°œ")
        print(f"  ë§¤ì¹­ë¥ : {link_match_rate:.1f}%")
        
        # ë…¸ë“œ ë§¤ì¹­ ê²°ê³¼
        total_nodes = len(enhanced_node_df)
        matched_nodes = enhanced_node_df['road_width'].notna().sum()
        node_match_rate = (matched_nodes / total_nodes) * 100
        
        print(f"\nğŸ“ ë…¸ë“œ ë°ì´í„° ë§¤ì¹­ ê²°ê³¼:")
        print(f"  ì´ ë…¸ë“œ ìˆ˜: {total_nodes}ê°œ")
        print(f"  ë„ë¡œ í­ ë§¤ì¹­ ì„±ê³µ: {matched_nodes}ê°œ") 
        print(f"  ë§¤ì¹­ë¥ : {node_match_rate:.1f}%")
        
        # ë„ë¡œ í­ í†µê³„
        if matched_links > 0:
            width_stats = enhanced_link_df['road_width'].dropna()
            print(f"\nğŸ“Š ë„ë¡œ í­ í†µê³„ (ë§í¬ ê¸°ì¤€):")
            print(f"  í‰ê·  ë„ë¡œ í­: {width_stats.mean():.1f}m")
            print(f"  ìµœì†Œ ë„ë¡œ í­: {width_stats.min()}m")
            print(f"  ìµœëŒ€ ë„ë¡œ í­: {width_stats.max()}m")
            print(f"  ì¤‘ê°„ê°’: {width_stats.median():.1f}m")
        
        print("\n" + "="*60)


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ìˆ˜ì •
def main():
    KAKAO_API_KEY = "c5ebe192c3d007a46ea0deb05f0ea12e"
    CSV_FILE_PATH = "/Users/gamjawon/Downloads/ë¶€ì‚°ê´‘ì—­ì‹œ_ë„ë¡œêµ¬ê°„ì¡°ì„œ_20250423.csv"
    
    integrator = RoadWidthIntegrator(KAKAO_API_KEY)
    
    print("ğŸš€ ë„ë¡œ í­ ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ ì‹œì‘ (ì¤‘ë‹¨ ì¬ì‹œì‘ ì§€ì›)")
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    try:
        node_df = pd.read_csv('/Users/gamjawon/busan_node_with_difficulty_all.csv')
        link_df = pd.read_csv('/Users/gamjawon/busan_link_with_difficulty_all.csv')
        print(f"âœ… ë…¸ë“œ ë°ì´í„°: {len(node_df)}ê°œ")
        print(f"âœ… ë§í¬ ë°ì´í„°: {len(link_df)}ê°œ")
    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return
    
    # ë„ë¡œ í­ ë°ì´í„° ë¡œë“œ
    try:
        road_width_df = integrator.load_road_width_csv(CSV_FILE_PATH)
        print(f"âœ… ë„ë¡œ í­ ë°ì´í„°: {len(road_width_df)}ê°œ")
    except Exception as e:
        print(f"âŒ ë„ë¡œ í­ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ì¢Œí‘œ ì •ë³´ ì¶”ê°€ (ì¤‘ë‹¨ ì¬ì‹œì‘ ì§€ì›)
    print("\nğŸ—ºï¸ ì¹´ì¹´ì˜¤ APIë¡œ ì¢Œí‘œ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
    print("ğŸ’¡ ì¤‘ë‹¨ëœ ê²½ìš° ë™ì¼í•œ ëª…ë ¹ì–´ë¡œ ì¬ì‹œì‘í•˜ë©´ ì´ì–´ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
    
    try:
        road_coord_df = integrator.create_coordinate_mapping_with_resume(road_width_df)
        integrator.get_api_usage_report()
        
        if len(road_coord_df) > 0:
            print(f"âœ… ì¢Œí‘œ ë§¤í•‘ ì™„ë£Œ: {len(road_coord_df)}ê°œ")
            
            # ë‚˜ë¨¸ì§€ ì²˜ë¦¬ ê³„ì†...
            enhanced_link_df = integrator.match_road_width_to_links(road_coord_df, link_df)
            enhanced_node_df = integrator.match_road_width_to_nodes(road_coord_df, node_df)
            integrator.save_results(enhanced_link_df, enhanced_node_df, road_coord_df)
            integrator.generate_summary_report(enhanced_link_df, enhanced_node_df, road_coord_df)
            
            # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬
            if os.path.exists(integrator.checkpoint_file):
                os.remove(integrator.checkpoint_file)
                print("ğŸ§¹ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¾ ì§„í–‰ìƒí™©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë™ì¼í•œ ëª…ë ¹ì–´ë¡œ ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        integrator.get_api_usage_report()


if __name__ == "__main__":
    main()